{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b947c78e",
      "metadata": {
        "id": "b947c78e"
      },
      "source": [
        "<font color='green'>\n",
        "Installing LangChain package\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8236fd59",
      "metadata": {
        "id": "8236fd59"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain==0.3.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2085724",
      "metadata": {
        "id": "e2085724"
      },
      "source": [
        "## Gemini Pro - Let's use the LLM provided by Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4f9984",
      "metadata": {
        "id": "eb4f9984"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain-google-genai==2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f274e9c5",
      "metadata": {
        "id": "f274e9c5"
      },
      "source": [
        "<font color='green'>\n",
        "Imports the Python built-in module called \"os.\"\n",
        "<br>Provide your api key to access gemini\n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ba8425",
      "metadata": {
        "id": "18ba8425"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your_api_key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4188048e",
      "metadata": {
        "id": "4188048e"
      },
      "outputs": [],
      "source": [
        "# We can access Google AIâ€™s gemini and gemini-vision models, as well as other generative models\n",
        "# through ChatGoogleGenerativeAI class in the langchain-google-genai integration package.\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a0f2a8",
      "metadata": {
        "id": "d2a0f2a8"
      },
      "source": [
        "<font color='green'>\n",
        "Here language model is represented by the object \"llm,\" which is being utilized to generate a completion or response based on a specific query.\n",
        "<br><br>\n",
        "The query, stored in the \"our_query\" variable is bieng passed to the model through llm object.\n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9548eede",
      "metadata": {
        "id": "9548eede"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
        "our_query = \"What is the currency of USA?\"\n",
        "result = llm.invoke(our_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "259e2628",
      "metadata": {
        "id": "259e2628",
        "outputId": "6de9d49c-b155-4d3c-c9f9-b56203afb945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indian Rupee (INR)\n"
          ]
        }
      ],
      "source": [
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9f977e",
      "metadata": {
        "id": "cb9f977e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}